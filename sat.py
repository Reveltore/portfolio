# -*- coding: utf-8 -*-
"""sat

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e4T4tEoseQGdhbPFJ8EEkAo1udKvzDQb
"""

!git clone https://github.com/Reveltore/portfolio.git

import pandas as pd
import numpy as np
import matplotlib as mpl
import re
import folium
from folium import plugins
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

files = ["ap_2010.csv", "class_size.csv", "demographics.csv", "graduation.csv", "hs_directory.csv", "math_test_results.csv", "sat_results.csv"]

data = {}
for f in files:
    d = pd.read_csv("schools/{0}".format(f))
    data[f.replace(".csv", "")] = d

for k,v in data.items():
    print("\n" + k + "\n")
    print(v.head())

ap_2010 = data['ap_2010']
ap_2010.head()

class_size = data['class_size']
class_size.head()

from numpy.lib.function_base import append

#Добавляет ведущих нулей столько, чтобы длина строк в class_size['CSD'] была 2
class_size['CSD'] = class_size['CSD'].apply('{:0>2}'.format)

class_size.head()

class_size.info()

# Соединяю столбы CSD, school_code, которые в сумме равны DBN и соответственно переименую
class_size['DBN'] = class_size['CSD'] + class_size['SCHOOL CODE']

class_size = class_size[class_size["GRADE "] == '09-12']
class_size = class_size[class_size['PROGRAM TYPE'] == 'GEN ED']
class_size = class_size.groupby('DBN').agg(np.mean)
class_size.reset_index(inplace = True)
data["class_size"] = class_size
class_size.head()

demogr = data['demographics']
demogr.head()

demogr = demogr[demogr['schoolyear'] == 20112012]
data["demographics"] = demogr
demogr.head()

data["math_test_results"] = data["math_test_results"][data["math_test_results"]["Year"] == 2011]
data["math_test_results"] = data["math_test_results"][data["math_test_results"]["Grade"] == 3]
math_test_res = data["math_test_results"]

math_test_res.head()

data["graduation"] = data["graduation"][data["graduation"]["Cohort"] == "2006"]
data["graduation"] = data["graduation"][data["graduation"]["Demographic"] == "Total Cohort"]
grad = data['graduation']
grad.head()

hs_direct = data['hs_directory']
hs_direct.rename(columns={'dbn':'DBN'}, inplace=True)
hs_direct.head()

hs_direct.head(
)

def lat(hs_direct_):
  hs_direct_=re.findall(r'\(.+\)', hs_direct_)
  hs_direct_ = [x.replace('(', '') for x in hs_direct_]
  for line in hs_direct_:
    Type = line.split(",")
    lati = Type[0]
    

 
  return lati

def lon(hs_direct_):
  hs_direct_=re.findall(r'\(.+\)', hs_direct_)
  hs_direct_ = [x.replace(')', '') for x in hs_direct_]
  for line in hs_direct_:
    Type = line.split(",")
    lon = Type[1]

 
  return lon

hs_direct['lat'] = hs_direct['Location 1'].apply(lat)
hs_direct['lon'] = hs_direct['Location 1'].apply(lon)

hs_direct['lat'] = pd.to_numeric(hs_direct['lat'], errors = 'coerce')
hs_direct['lon'] = pd.to_numeric(hs_direct['lon'] , errors = 'coerce')

hs_direct= hs_direct.loc[:, ["DBN", "school_name", "borough", "grade_span_min", "grade_span_max", "city", "total_students", "school_type", "program_highlights", "language_classes", "Location 1", "lat", "lon"]]

sat_results = data['sat_results']
sat_results.head()

sat_results['SAT Critical Reading Avg. Score'] =  pd.to_numeric(sat_results['SAT Critical Reading Avg. Score'], errors = 'coerce')
sat_results['SAT Math Avg. Score'] = pd.to_numeric(sat_results['SAT Math Avg. Score'], errors = 'coerce')
sat_results['SAT Writing Avg. Score'] = pd.to_numeric(sat_results['SAT Writing Avg. Score'], errors = 'coerce')

sat_results['sat_score'] = sat_results['SAT Critical Reading Avg. Score'] + sat_results['SAT Math Avg. Score'] +  sat_results['SAT Writing Avg. Score']

sat_results.head()

s_all = pd.read_csv('survey_all.txt',delimiter="\t", encoding="windows-1252")
s_75d = pd.read_csv('survey_d75.txt',delimiter="\t", encoding="windows-1252")

s_all_75 = pd.concat([s_all, s_75d], axis = 0)
s_all_75 = s_all_75.rename(columns={'dbn': 'DBN'})
s_all_75.head()

s_all_75.info()

s_fin = s_all_75.loc[:, ["DBN", "rr_s", "rr_t", "rr_p", "N_s", "N_t", "N_p", "saf_p_11", "com_p_11", "eng_p_11", "aca_p_11", "saf_t_11", "com_t_11", "eng_t_11", "aca_t_11", "saf_s_11", "com_s_11", "eng_s_11", "aca_s_11", "saf_tot_11", "com_tot_11", "eng_tot_11", "aca_tot_11"]]
s_fin.head()

# inner 
all = sat_results.merge(ap_2010, on = 'DBN', how = 'inner')
all = all.merge(grad, on = 'DBN', how = 'inner')
all = all.merge(demogr, on = 'DBN', how = 'inner')
all = all.merge(hs_direct, on = 'DBN', how = 'inner')
# outer
all = all.merge(math_test_res ,on = 'DBN', how = 'outer')
# left
all = all.merge(s_fin, on = 'DBN', how = 'left')

all = all.drop_duplicates(subset=['DBN'])

all.head()

all.shape

all['school_dist'] = all['DBN']. apply(lambda x : x[:2])

#К числам
all['AP Test Takers '] =  pd.to_numeric(all['AP Test Takers '], errors = 'coerce')
all['Total Exams Taken'] = pd.to_numeric(all['Total Exams Taken'], errors = 'coerce')
all['Number of Exams with scores 3 4 or 5'] = pd.to_numeric(all['Number of Exams with scores 3 4 or 5'], errors = 'coerce')

#Пропуски на средние
all['AP Test Takers '] = all['AP Test Takers '].fillna(all['AP Test Takers '].mean())
all['Total Exams Taken'] = all['Total Exams Taken'].fillna(all['Total Exams Taken'].mean())
all['Number of Exams with scores 3 4 or 5'] = all['Number of Exams with scores 3 4 or 5'].fillna(all['Number of Exams with scores 3 4 or 5'].mean())

all.corr()['sat_score']

#Прямая сильная кор - Total Regents - % of cohort, Advanced Regents - % of cohort, Advanced Regents - % of grads,Regents w/o Advanced - % of cohort

map = folium.Map(location = [all['lat'].mean(), all['lon'].mean()], zoom_start=10)
marker_cluster = folium.plugins.MarkerCluster().add_to(map)

for name, row in all.iterrows():
    folium.Marker([row["lat"], row["lon"]], popup="{0}: {1}".format(row["DBN"], row["school_name"])).add_to(marker_cluster)

import folium
from folium import plugins

map = folium.Map(location=[all['lat'].mean(), all['lon'].mean()], zoom_start=10)
marker_cluster = folium.plugins.MarkerCluster().add_to(map)
for name, row in all.iterrows():
    folium.Marker([row["lat"], row["lon"]], popup="{0}: {1}".format(row["DBN"], row["school_name"])).add_to(marker_cluster)
map.save('schools.html')
map

heatmap = folium.Map(location = [all['lat'].mean(), all['lon'].mean()], zoom_start = 10)
heatmap.add_children(plugins.HeatMap([[row["lat"], row["lon"]] for name,row in all.iterrows()])) 
heatmap.save('heatmap.html')
heatmap

#Корреляция результатов SAT с опросами
all.corr()['sat_score'][['rr_t', 'rr_t', 'rr_p', 'N_s', 'N_t', 'N_p', 'saf_tot_11', 'com_tot_11', 'aca_tot_11', 'eng_tot_11']].plot.bar()

# Успеваемость учеников разной расы
all.corr()["sat_score"][["white_per", "asian_per", "black_per", "hispanic_per"]].plot.bar()

#Половые различия
all.corr()["sat_score"][["male_per", "female_per"]].plot.bar()
all.plot.scatter(x='female_per', y='sat_score')

#Лучшие школы исходя из скаттера
all[(all["female_per"] > 65) & (all["sat_score"] > 1400)]["School Name"]