{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e175142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22266f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67900d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform= tv.transforms.ToTensor(),download = True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform= tv.transforms.ToTensor(),download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118b7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e169e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f6c1911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 16*120\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81eb4a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=4, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(6, 16, kernel_size=4),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    nn.Conv2d(16, 120, kernel_size=4, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3000,512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefc834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = torch.Tensor([0]), 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(axis = 1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad325f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, optimizer, num_epochs):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0,0.0,0, time.time()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) ==y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(f'epoch{epoch + 1}, loss {train_l_sum/ n:.4f}, train_acc{train_acc_sum/n:.3f}' \\\n",
    "              f', test_acc{test_acc:.3f}, time {time.time() - start:.1f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe527efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1, loss 0.0005, train_acc0.903, test_acc0.898, time 198.0 sec\n",
      "epoch2, loss 0.0004, train_acc0.917, test_acc0.904, time 193.1 sec\n",
      "epoch3, loss 0.0004, train_acc0.923, test_acc0.907, time 195.4 sec\n",
      "epoch4, loss 0.0004, train_acc0.930, test_acc0.914, time 203.5 sec\n",
      "epoch5, loss 0.0003, train_acc0.936, test_acc0.909, time 198.9 sec\n",
      "epoch6, loss 0.0003, train_acc0.942, test_acc0.906, time 196.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "num_epochs = 6\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, train_iter, test_iter, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
