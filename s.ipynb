{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8359b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e3e9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e07570ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train = True, transform = tv.transforms.ToTensor(), download = True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train = False, transform = tv.transforms.ToTensor(), download = True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65b347cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd142693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "86fe1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512,256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(64),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(32),\n",
    "    torch.nn.Linear(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d82ca641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (14): ReLU()\n",
       "  (15): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d228d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ccdb7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for ep in range(num_epoch):\n",
    "        train_iters, train_passed  = 0, 0\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train:\n",
    "            trainer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            train_iters += 1\n",
    "            train_passed += len(X)\n",
    "        \n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "        if ep % 5 ==0:   \n",
    "            print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c7bdb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 56.703, train_loss: 0.5324287252911066, train_acc: 0.8110666666666667, test_loss: 0.5665730118751526, test_acc: 0.7918\n",
      "ep: 5, taked: 56.185, train_loss: 0.2909188391798634, train_acc: 0.8920833333333333, test_loss: 0.44454423040151597, test_acc: 0.8494\n",
      "ep: 10, taked: 56.625, train_loss: 0.2391800908213955, train_acc: 0.9106833333333333, test_loss: 0.39038146287202835, test_acc: 0.8683\n",
      "ep: 15, taked: 56.752, train_loss: 0.20400924961698258, train_acc: 0.9233666666666667, test_loss: 0.40426419824361803, test_acc: 0.8737\n",
      "ep: 20, taked: 56.547, train_loss: 0.17364387400448322, train_acc: 0.93435, test_loss: 0.40046951174736023, test_acc: 0.8802\n",
      "ep: 25, taked: 56.668, train_loss: 0.14838137225074283, train_acc: 0.9437, test_loss: 0.4776037335395813, test_acc: 0.8698\n",
      "ep: 30, taked: 56.552, train_loss: 0.1298951634474225, train_acc: 0.95145, test_loss: 0.4482993856072426, test_acc: 0.8788\n",
      "ep: 35, taked: 56.560, train_loss: 0.11355972147972906, train_acc: 0.9579166666666666, test_loss: 0.48975185602903365, test_acc: 0.8745\n",
      "ep: 40, taked: 56.470, train_loss: 0.09825333795052464, train_acc: 0.9632, test_loss: 0.5373379096388817, test_acc: 0.8714\n",
      "ep: 45, taked: 56.507, train_loss: 0.08604739387361807, train_acc: 0.9684, test_loss: 0.5975484386086464, test_acc: 0.8757\n",
      "ep: 50, taked: 56.536, train_loss: 0.07459376832880711, train_acc: 0.9721666666666666, test_loss: 0.5927372083067894, test_acc: 0.8763\n",
      "ep: 55, taked: 56.322, train_loss: 0.060855016467492966, train_acc: 0.9762333333333333, test_loss: 0.5753768295049667, test_acc: 0.8818\n",
      "ep: 60, taked: 56.099, train_loss: 0.05306149560216246, train_acc: 0.9792166666666666, test_loss: 0.6518062859773636, test_acc: 0.8761\n",
      "ep: 65, taked: 57.586, train_loss: 0.04455722862128484, train_acc: 0.9832333333333333, test_loss: 0.6561817765235901, test_acc: 0.8822\n",
      "ep: 70, taked: 62.718, train_loss: 0.0441872140222971, train_acc: 0.9835666666666667, test_loss: 0.76575408577919, test_acc: 0.8724\n",
      "ep: 75, taked: 65.744, train_loss: 0.03663092532680544, train_acc: 0.9862666666666666, test_loss: 0.7914885699748992, test_acc: 0.8785\n",
      "ep: 80, taked: 66.184, train_loss: 0.034605589616349186, train_acc: 0.9874, test_loss: 0.8360517978668213, test_acc: 0.877\n",
      "ep: 85, taked: 63.363, train_loss: 0.03182980821515292, train_acc: 0.9878166666666667, test_loss: 0.7589086621999741, test_acc: 0.8841\n",
      "ep: 90, taked: 63.514, train_loss: 0.028704223982196585, train_acc: 0.98955, test_loss: 0.7857063561677933, test_acc: 0.8831\n",
      "ep: 95, taked: 63.445, train_loss: 0.02368551696664496, train_acc: 0.99185, test_loss: 0.8925829261541367, test_acc: 0.8775\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
